{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74n-E3IWvWaf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def download_and_setup_test_dataset():\n",
    "    \"\"\"\n",
    "    Downloading the test dataset.\n",
    "    \"\"\"\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/test_database.tar')\n",
    "\n",
    "    datasets_path = \"datasets\"\n",
    "    if not os.path.exists(datasets_path):\n",
    "        os.makedirs(datasets_path)\n",
    "\n",
    "    # put the test dataset in datasets/test\n",
    "    os.system(\"tar xf test_database.tar -C 'datasets' --one-top-level && mv test_database.tar datasets/test\")\n",
    "\n",
    "\n",
    "def download_and_setup_small_dataset():\n",
    "    \"\"\"\n",
    "    Downloading the small dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_small.tar')\n",
    "\n",
    "    datasets_path = \"datasets\"\n",
    "    if not os.path.exists(datasets_path):\n",
    "        os.makedirs(datasets_path)\n",
    "\n",
    "    # put the small dataset in datasets/small\n",
    "    os.system(\n",
    "        \"tar xf defi1certif-datasets-fire_small.tar -C 'datasets' --one-top-level && mv \"\n",
    "        \"datasets/defi1certif-datasets-fire_small datasets/small\")\n",
    "\n",
    "\n",
    "def download_and_setup_medium_dataset():\n",
    "    \"\"\"\n",
    "    Downloading the medium dataset.\n",
    "    \"\"\"\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_medium.tar.001')\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_medium.tar.002')\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_medium.tar.003')\n",
    "\n",
    "    datasets_path = \"datasets\"\n",
    "    if not os.path.exists(datasets_path):\n",
    "        os.makedirs(datasets_path)\n",
    "\n",
    "    # recombine the tar files\n",
    "    os.system(\"cat  defi1certif-datasets-fire_medium.tar.001 defi1certif-datasets-fire_medium.tar.002 \"\n",
    "              \"defi1certif-datasets-fire_medium.tar.003 >> defi1certif-datasets-fire_medium.tar\")\n",
    "\n",
    "    # put the medium dataset in datasets/medium\n",
    "    os.system(\"tar xf defi1certif-datasets-fire_medium.tar -C 'datasets' --one-top-level && mv \"\n",
    "              \"datasets/defi1certif-datasets-fire_medium datasets/medium\")\n",
    "\n",
    "\n",
    "def download_and_setup_large_dataset():\n",
    "    \"\"\"\n",
    "    Downloading the large dataset.\n",
    "    \"\"\"\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_big.tar.001')\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_big.tar.002')\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_big.tar.003')\n",
    "    os.system(\n",
    "        'wget https://github.com/belarbi2733/keras_yolov3/releases/download/1/defi1certif-datasets-fire_big.tar.004')\n",
    "\n",
    "    datasets_path = \"datasets\"\n",
    "    if not os.path.exists(datasets_path):\n",
    "        os.makedirs(datasets_path)\n",
    "\n",
    "    # recombine the tar files\n",
    "    os.system(\"cat  defi1certif-datasets-fire_big.tar.001 defi1certif-datasets-fire_big.tar.002 \"\n",
    "              \"defi1certif-datasets-fire_big.tar.003 defi1certif-datasets-fire_big.tar.004 >> \"\n",
    "              \"defi1certif-datasets-fire_big.tar\")\n",
    "\n",
    "    # put the large dataset in datasets/large\n",
    "    os.system(\"tar xf defi1certif-datasets-fire_big.tar -C 'datasets' --one-top-level && mv \"\n",
    "              \"datasets/defi1certif-datasets-fire_big datasets/large\")\n",
    "\n",
    "\n",
    "def setup_full_dataset():\n",
    "    \"\"\"\n",
    "    Downloads and sets up all datasets in a single folder named all.\n",
    "    A folder per class is created.\n",
    "    \"\"\"\n",
    "    download_and_setup_small_dataset()\n",
    "    download_and_setup_medium_dataset()\n",
    "    download_and_setup_large_dataset()\n",
    "\n",
    "    # creating the folder to merge datasets\n",
    "    if not os.path.exists(\"datasets/all\"):\n",
    "        os.makedirs(\"datasets/all\")\n",
    "    if not os.path.exists(\"datasets/all/fire\"):\n",
    "        os.makedirs(\"datasets/all/fire\")\n",
    "    if not os.path.exists(\"datasets/all/no_fire\"):\n",
    "        os.makedirs(\"datasets/all/no_fire\")\n",
    "    if not os.path.exists(\"datasets/all/start_fire\"):\n",
    "        os.makedirs(\"datasets/all/start_fire\")\n",
    "\n",
    "    # moving images from the small dataset to the full dataset\n",
    "    os.system(\"find datasets/small/fire -type f -print0 | xargs -0 mv -t datasets/all/fire/\")\n",
    "    os.system(\"find datasets/small/no_fire -type f -print0 | xargs -0 mv -t datasets/all/no_fire/\")\n",
    "    os.system(\"find datasets/small/start_fire -type f -print0 | xargs -0 mv -t datasets/all/start_fire/\")\n",
    "\n",
    "    # moving images from the medium dataset to the full dataset\n",
    "    os.system(\"find datasets/medium/fire -type f -print0 | xargs -0 mv -t datasets/all/fire/\")\n",
    "    os.system(\"find datasets/medium/no_fire -type f -print0 | xargs -0 mv -t datasets/all/no_fire/\")\n",
    "    os.system(\"find datasets/medium/start_fire -type f -print0 | xargs -0 mv -t datasets/all/start_fire/\")\n",
    "\n",
    "    # moving images from the large dataset to the full dataset\n",
    "    os.system(\"find datasets/large/fire -type f -print0 | xargs -0 mv -t datasets/all/fire/\")\n",
    "    os.system(\"find datasets/large/no_fire -type f -print0 | xargs -0 mv -t datasets/all/no_fire/\")\n",
    "    os.system(\"find datasets/large/start_fire -type f -print0 | xargs -0 mv -t datasets/all/start_fire/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "V5QN-zlB-MgZ",
    "outputId": "8b945c75-1453-4e11-a649-49dd7c6f67ba"
   },
   "outputs": [],
   "source": [
    "import imghdr\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "classes = ['fire', 'no_fire', 'start_fire']\n",
    "nbr_classes = 3\n",
    "\n",
    "\n",
    "def generate_from_paths_and_labels(images_paths, labels, batch_size, preprocessing, image_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Generator to give to the fit function, generates batches of samples for training.\n",
    "    This avoids to load the full dataset in memory. This can also be a Keras class.\n",
    "    :param images_paths:\n",
    "    :param labels:\n",
    "    :param batch_size:\n",
    "    :param image_size:\n",
    "    :param preprocessing:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    number_samples = len(images_paths)\n",
    "    while 1:\n",
    "        perm = np.random.permutation(number_samples)  # randomize the order of the images (to be done after each epoch)\n",
    "\n",
    "        # apply the permutations\n",
    "        images_paths = images_paths[perm]\n",
    "        labels = labels[perm]\n",
    "\n",
    "        # from 0 to number_samples by batch_size increment to generate batches\n",
    "        # this assumes there are number_samples / batch_size batches in an epoch\n",
    "        # which ensures that each samples is only fed once to the network at each epoch\n",
    "        for i in range(0, number_samples, batch_size):\n",
    "            # a batch is a list of image paths : images_paths[i:i + batch_size]\n",
    "            # map transforms all paths to images using keras.preprocessing.image\n",
    "            inputs = list(map(\n",
    "                lambda x: image.load_img(x, target_size=image_size),\n",
    "                images_paths[i:i + batch_size]\n",
    "            ))\n",
    "            # converting the loaded images to numpy arrays\n",
    "            inputs = np.array(list(map(\n",
    "                lambda x: image.img_to_array(x),\n",
    "                inputs\n",
    "            )))\n",
    "\n",
    "            # preprocessing the batch might notably normalize between 0 and 1 the RGB values, this is model-dependant\n",
    "            inputs = preprocessing(inputs)\n",
    "\n",
    "            # yields the image batch and corresponding labels\n",
    "            yield (inputs, labels[i:i + batch_size])\n",
    "\n",
    "\n",
    "def extract_dataset(dataset_path, classes_names, percentage):\n",
    "    \"\"\"\n",
    "    Assumes that dataset_path/classes_names[0] is a folder containing all images of class classes_names[0].\n",
    "    All image paths are loaded into a numpy array, corresponding labels are one-hot encoded and put into a numpy array.\n",
    "    Samples are shuffled before splitting into training and validation sets to prevent problems since samples are loaded\n",
    "    in order of their class.\n",
    "    :param dataset_path: path to the root of the dataset.\n",
    "    :param classes_names: names of the classes.\n",
    "    :param percentage: percentage of samples to be used for training, the rest is for validation. Must be in [0,1].\n",
    "    :return: (x_train, y_train), (x_val, y_val) a list of image paths and a list of corresponding labels for training\n",
    "    and validation.\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes = len(classes_names)\n",
    "\n",
    "    # putting images paths and labels in lists\n",
    "    images_paths, labels = [], []\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        class_id = classes_names.index(class_name)  # class id = index of the class_name in classes_name, later o-h enc\n",
    "        # here we are considering all paths for images labeled class_id\n",
    "        for path in os.listdir(class_path):\n",
    "            path = os.path.join(class_path, path)  # image path\n",
    "            # test the image data contained in the file , and returns a string describing the image type\n",
    "            if imghdr.what(path) is None:\n",
    "                # this is not an image file\n",
    "                continue\n",
    "            images_paths.append(path)\n",
    "            labels.append(class_id)\n",
    "\n",
    "    # one-hot encode the labels\n",
    "    labels_oh = np_utils.to_categorical(labels, num_classes)\n",
    "    # convert images_paths to numpy array to apply permutation\n",
    "    images_paths = np.array(images_paths)\n",
    "\n",
    "    number_samples = len(images_paths)\n",
    "    perm = np.random.permutation(number_samples)\n",
    "    labels_oh = labels_oh[perm]\n",
    "    images_paths = images_paths[perm]\n",
    "\n",
    "    # 90% of samples used for training\n",
    "    border = math.floor(percentage * len(images_paths))\n",
    "\n",
    "    train_labels, val_labels = labels_oh[:border], labels_oh[border:]\n",
    "    train_samples, val_samples = images_paths[:border], images_paths[border:]\n",
    "\n",
    "    print(\"Training on %d samples\" % (len(train_samples)))\n",
    "    print(\"Validation on %d samples\" % (len(val_samples)))\n",
    "\n",
    "    return (train_samples, train_labels), (val_samples, val_labels)\n",
    "\n",
    "def graphically_test_model(model_path, classes_names, test_image_dir, preprocess_input, image_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads a model, does a prediction on each image in test_image_dir and displays the image with the class name on\n",
    "    top of it.\n",
    "    :param model_path:\n",
    "    :param classes_names:\n",
    "    :param test_image_dir:\n",
    "    :param preprocess_input:\n",
    "    :param image_size:\n",
    "    \"\"\"\n",
    "    nbr_classes = len(classes_names)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    for test_image_path in os.listdir(test_image_dir):\n",
    "        # load image using keras\n",
    "        img = image.load_img(test_image_dir + \"/\" + test_image_path, target_size=image_size)\n",
    "\n",
    "        # processed image to feed the network\n",
    "        processed_img = image.img_to_array(img)\n",
    "        processed_img = np.expand_dims(processed_img, axis=0)\n",
    "        processed_img = preprocess_input(processed_img)\n",
    "\n",
    "        # get prediction using the network\n",
    "        predictions = model.predict(processed_img)[0]\n",
    "        # transform [0,1] values into percentages and associate it to its class name (class_name order was used to\n",
    "        # one-hot encode the classes)\n",
    "        result = [(classes_names[i], float(predictions[i]) * 100.0) for i in range(nbr_classes)]\n",
    "        # sort the result by percentage\n",
    "        result.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "        # load image for displaying\n",
    "        img = cv2.imread(test_image_dir + \"/\" + test_image_path)\n",
    "        # transform into RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        # write class percentages on the image\n",
    "        for i in range(nbr_classes):\n",
    "            (class_name, prob) = result[i]\n",
    "            textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
    "            textX = (img.shape[1] - textsize[0]) / 2\n",
    "            textY = (img.shape[0] + textsize[1]) / 2\n",
    "            if (i == 0):\n",
    "                cv2.putText(img, class_name, (int(textX) - 100, int(textY)), font, 5, (255, 255, 255), 6, cv2.LINE_AA)\n",
    "            print(\"Top %d ====================\" % (i + 1))\n",
    "            print(\"Class name: %s\" % (class_name))\n",
    "            print(\"Probability: %.2f%%\" % (prob))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, classes, preprocessing, dataset_path):\n",
    "    \"\"\"\n",
    "    Loads a model and evaluates the model (metrics) on images provided in folder a dataset.\n",
    "    :param model_path:\n",
    "    :param classes:\n",
    "    :param preprocessing:\n",
    "    :param test_dataset:\n",
    "    \"\"\"\n",
    "    # For simplicity, the dataset is loaded using 99.9% of images\n",
    "    (train_samples, train_labels), (val_samples, val_labels) = extract_dataset(dataset_path, classes, 0)\n",
    "    batch_size = 16\n",
    "    nbr_val_samples = len(val_samples)\n",
    "    validation_sample_generator = generate_from_paths_and_labels(val_samples, val_labels, batch_size, preprocessing,\n",
    "                                                                 image_size=(224, 224, 3))\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    return model.evaluate_generator(validation_sample_generator, steps=math.ceil(nbr_val_samples / 16),\n",
    "                             max_queue_size=10, workers=1, use_multiprocessing=True, verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JC2NvDxemkco"
   },
   "outputs": [],
   "source": [
    "download_and_setup_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ARhaZq-w-PZm",
    "outputId": "ccc85756-04f8-455f-ed46-badb81c62b2e"
   },
   "outputs": [],
   "source": [
    "graphically_test_model(\"best_trained_save.h5\", classes, \"datasets/test_database/Base de données de test\", inception_preprocess_input, image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtH8OfdXBrgF"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_hard_samples(model_path, preprocess_input, dataset_path, threshold,image_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extracts samples which are ard to classify for the network. Takes a dataset and a model as input, prediction is\n",
    "    performed by the model on the samples from the dataset and samples with a classification confidence for the correct\n",
    "    class lower than threshold are saved to a list.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    classes = ['fire', 'no_fire', 'start_fire']\n",
    "    nbr_classes = 3\n",
    "\n",
    "    #model = load_model(model_path)\n",
    "\n",
    "    hard_examples = [[] for j in range(nbr_classes)]\n",
    "\n",
    "    for i in range(nbr_classes):\n",
    "        class_name = classes[i]\n",
    "        for sample_path in os.listdir(dataset_path+\"/\"+class_name):\n",
    "            print(sample_path)\n",
    "            img = image.load_img(sample_path, target_size=image_size)\n",
    "            # processed image to feed the network\n",
    "            processed_img = image.img_to_array(img)\n",
    "            processed_img = np.expand_dims(processed_img, axis=0)\n",
    "            processed_img = preprocess_input(processed_img)\n",
    "\n",
    "            # get prediction using the network\n",
    "            predictions = model.predict(processed_img)[0]\n",
    "\n",
    "            # prediction is not satisfactory\n",
    "            if predictions[i] < threshold:\n",
    "                hard_examples[i].append(sample_path)\n",
    "\n",
    "    return hard_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQAFuyFMmueE"
   },
   "outputs": [],
   "source": [
    "setup_full_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-YTG-Cmm8Yc"
   },
   "outputs": [],
   "source": [
    "def show_hard_samples(hard_examples, dataset_path):\n",
    "    \"\"\"\n",
    "    Displays hard samples to classify. Samples must be in 1x3 list.\n",
    "    \"\"\"\n",
    "\n",
    "    classes = ['fire', 'no_fire', 'start_fire']\n",
    "    nbr_classes = 3\n",
    "\n",
    "    for i in range(nbr_classes):\n",
    "        class_name = classes[i]\n",
    "        print(\"======= IMAGES OF \"+class_name+\" ========\")\n",
    "        for sample_path in hard_examples[i]:\n",
    "            # load image for displaying\n",
    "            img = cv2.imread(dataset_path + \"/\" + class_name + \"/\" + sample_path)\n",
    "            # transform into RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nTR58q5UnBqc",
    "outputId": "d7e89c73-b1ee-4a60-e41c-23b8ef7e8e27"
   },
   "outputs": [],
   "source": [
    "# 0.33 threshold on all\n",
    "third = [['913_0.jpg', '00000253.jpg', '00000386.jpg', 'maison (85).png', '00000185.jpg'], ['maisonbis (1).png', 'Autumn (13).png', '00000264.jpg', 'NorthAmerica (14).png', '46.png', '00000149.jpg', 'Nature15.jpg', 'Wheat3.jpg'], ['NorthAmerica (4).png', '12.png', '133.png', '00000169.jpg', '00000162.jpg', '166.png', '118.png', '00000172.jpg', '13.png', '00000143.jpg', '00000065.jpg', '129.png', '116.png', '00000064.jpg', '128.png', '177.png', '182.png', '130.png', '181.png', '00000121.jpg', '178.png', '183.png', '00000157.jpg', 'Orgon (33).png', '126.png', '185.png', '0.png', '00000129.jpg', 'SaintCana (43).png']]\n",
    "\n",
    "show_hard_samples(third,\"datasets/all/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "boJOhunWz6Nz",
    "outputId": "81af79e8-27ac-451a-eff3-398e59fd50a6"
   },
   "outputs": [],
   "source": [
    "# 0.6 threshold on all\n",
    "sixty = [['Athenesbis (12).png', 'California (82).png', '913_0.jpg', '00000386.jpg', 'Orgon (99).png', '00000185.jpg', '00000043.jpg', '2970的副本.png', '00000339.jpg', 'maison (85).png', 'Orgon (123).png', '00000253.jpg', '00000380.jpg', '92983122.jpg'], ['maisonbis (1).png', 'Problem-smoke-bedroom.jpg', '46.png', 'NorthAmerica (6).png', '00000149.jpg', 'Autumn (13).png', 'NorthAmerica (14).png', '00000144.jpg', 'Wheat3.jpg', 'maisonbis (2).png', '00000264.jpg', 'Nature15.jpg'], ['177.png', 'Trompe (16).png', '121.png', '128.png', '00000161.jpg', '00000068.jpg', 'Orgon (33).png', '00000162.jpg', '184.png', '132.png', '185.png', '126.png', '166.png', 'Trompe (15).png', '133.png', '130.png', 'NorthAmerica (73).png', '129.png', '00000143.jpg', 'NorthAmerica (4).png', '00000064.jpg', '00000026.jpg', '195.png', '179.png', '167.png', '178.png', '13.png', '12.png', '134.png', '183.png', 'hesitationBormesMisomas (73).png', '00000065.jpg', '189.png', '00000172.jpg', '135.png', 'SaintCana (43).png', 'SaintCana (325).png', '00000121.jpg', '0.png', '116.png', '00000129.jpg', '118.png', '181.png', '00000055.jpg', '00000169.jpg', '182.png', '00000157.jpg', '180.png', '117.png', 'maisonbisbis (8).png', '00000125.jpg']]\n",
    "show_hard_samples(sixty,\"datasets/all/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lAV-nqR58az"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
